{"cells":[{"metadata":{},"cell_type":"markdown","source":"Cloning Efficientnet repository "},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install -U efficientnet","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.0-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 2.3 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet) (0.16.2)\nRequirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\nRequirement already satisfied, skipping upgrade: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.1)\nRequirement already satisfied, skipping upgrade: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (3.2.1)\nRequirement already satisfied, skipping upgrade: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.4)\nRequirement already satisfied, skipping upgrade: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (5.4.1)\nRequirement already satisfied, skipping upgrade: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.8.0)\nRequirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.1.1)\nRequirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.14.0)\nRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\nRequirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\nRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\nRequirement already satisfied, skipping upgrade: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.0 keras-applications-1.0.8\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Loading Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import packages\nimport os, gc\nimport numpy as np\nimport pandas as pd\nimport glob\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\n\n# deep learning\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.activations import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras.preprocessing.image import *\n\nprint(f'Tensorflow Version: ', tf.__version__)\nprint(f'Keras Version: ', tf.keras.__version__)","execution_count":2,"outputs":[{"output_type":"stream","text":"Tensorflow Version:  2.2.0\nKeras Version:  2.3.0-tf\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Preparing Data\n\n## Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = Path('../input/covidpreprocesseddata/train_224x224-20200626T124445Z-001/train_224x224/')\nos.listdir(data)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"['Normal', 'Others', 'Covid']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for class_ in os.listdir(data):\n    print(f'Number of train-val images in {class_}: {len(os.listdir(os.path.join(data, class_)))}')","execution_count":4,"outputs":[{"output_type":"stream","text":"Number of train-val images in Normal: 695\nNumber of train-val images in Others: 611\nNumber of train-val images in Covid: 695\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Making dataframe from images inside directories. We will use this df to generate our folds."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Paths to respective folders\nnormal = data / 'Normal'\ncovid = data / 'Covid'\nothers = data / 'Others'\n\n# image files in respective dir\ncovid_cases = covid.glob('*.png')\nnormal_cases = normal.glob('*.png')\nothers_cases = others.glob('*.png')\n\ntrain_data = []\n\nfor img in normal_cases:\n    train_data.append((str(img), 'Normal'))\n    \nfor img in covid_cases:\n    train_data.append((str(img), 'Covid'))\n    \nfor img in others_cases:\n    train_data.append((str(img), 'Others'))\n\n# making train_data dataframe    \ntrain_data = pd.DataFrame(train_data, columns=['path', 'label'], index=None)\ntrain_data","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                                                   path   label\n0     ../input/covidpreprocesseddata/train_224x224-2...  Normal\n1     ../input/covidpreprocesseddata/train_224x224-2...  Normal\n2     ../input/covidpreprocesseddata/train_224x224-2...  Normal\n3     ../input/covidpreprocesseddata/train_224x224-2...  Normal\n4     ../input/covidpreprocesseddata/train_224x224-2...  Normal\n...                                                 ...     ...\n1996  ../input/covidpreprocesseddata/train_224x224-2...  Others\n1997  ../input/covidpreprocesseddata/train_224x224-2...  Others\n1998  ../input/covidpreprocesseddata/train_224x224-2...  Others\n1999  ../input/covidpreprocesseddata/train_224x224-2...  Others\n2000  ../input/covidpreprocesseddata/train_224x224-2...  Others\n\n[2001 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Others</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Others</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Others</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Others</td>\n    </tr>\n    <tr>\n      <th>2000</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Others</td>\n    </tr>\n  </tbody>\n</table>\n<p>2001 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Testing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = Path('../input/covidpreprocesseddata/test-20200626T124450Z-001/test/')\nos.listdir(test_data)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"['Normal', 'Others', 'Covid']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for class_ in os.listdir(test_data):\n    print(f'Number of test images in {class_}: {len(os.listdir(os.path.join(test_data, class_)))}')","execution_count":7,"outputs":[{"output_type":"stream","text":"Number of test images in Normal: 100\nNumber of test images in Others: 100\nNumber of test images in Covid: 100\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing test data\n\nnormal_test = test_data / 'Normal'\ncovid_test = test_data / 'Covid'\nothers_test = test_data / 'Others'\n\ncovid_cases_test = covid_test.glob('*.png')\nnormal_cases_test = normal_test.glob('*.png')\nothers_cases_test = others_test.glob('*.png')\n\ntest_data = []\n\nfor img in normal_cases_test:\n    test_data.append((str(img), 'Normal'))\n    \nfor img in covid_cases_test:\n    test_data.append((str(img), 'Covid'))\n    \nfor img in others_cases_test:\n    test_data.append((str(img), 'Others'))\n    \n# test_data dataframe    \ntest_data = pd.DataFrame(test_data, columns=['path', 'label'], index=None)\ntest_data","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"                                                  path   label\n0    ../input/covidpreprocesseddata/test-20200626T1...  Normal\n1    ../input/covidpreprocesseddata/test-20200626T1...  Normal\n2    ../input/covidpreprocesseddata/test-20200626T1...  Normal\n3    ../input/covidpreprocesseddata/test-20200626T1...  Normal\n4    ../input/covidpreprocesseddata/test-20200626T1...  Normal\n..                                                 ...     ...\n295  ../input/covidpreprocesseddata/test-20200626T1...  Others\n296  ../input/covidpreprocesseddata/test-20200626T1...  Others\n297  ../input/covidpreprocesseddata/test-20200626T1...  Others\n298  ../input/covidpreprocesseddata/test-20200626T1...  Others\n299  ../input/covidpreprocesseddata/test-20200626T1...  Others\n\n[300 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/covidpreprocesseddata/test-20200626T1...</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/covidpreprocesseddata/test-20200626T1...</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/covidpreprocesseddata/test-20200626T1...</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/covidpreprocesseddata/test-20200626T1...</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/covidpreprocesseddata/test-20200626T1...</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>../input/covidpreprocesseddata/test-20200626T1...</td>\n      <td>Others</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>../input/covidpreprocesseddata/test-20200626T1...</td>\n      <td>Others</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>../input/covidpreprocesseddata/test-20200626T1...</td>\n      <td>Others</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>../input/covidpreprocesseddata/test-20200626T1...</td>\n      <td>Others</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>../input/covidpreprocesseddata/test-20200626T1...</td>\n      <td>Others</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## K-folds Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# k-fold cross -validation\ntrain_data[\"kfold\"] = -1    \ntrain_data = train_data.sample(frac=1).reset_index(drop=True)\ny = train_data.label.values\nkf = StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(kf.split(X=train_data, y=y)):\n    train_data.loc[v_, 'kfold'] = f\n\n# saving train_data with kfold column\ntrain_data.to_csv(\"train_folds.csv\", index=False)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"                                                   path   label  kfold\n0     ../input/covidpreprocesseddata/train_224x224-2...  Others      0\n1     ../input/covidpreprocesseddata/train_224x224-2...   Covid      0\n2     ../input/covidpreprocesseddata/train_224x224-2...  Others      0\n3     ../input/covidpreprocesseddata/train_224x224-2...  Others      0\n4     ../input/covidpreprocesseddata/train_224x224-2...  Normal      0\n...                                                 ...     ...    ...\n1996  ../input/covidpreprocesseddata/train_224x224-2...  Normal      4\n1997  ../input/covidpreprocesseddata/train_224x224-2...  Others      4\n1998  ../input/covidpreprocesseddata/train_224x224-2...  Normal      4\n1999  ../input/covidpreprocesseddata/train_224x224-2...  Others      4\n2000  ../input/covidpreprocesseddata/train_224x224-2...  Normal      4\n\n[2001 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Others</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Covid</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Others</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Others</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Normal</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Normal</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Others</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Normal</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Others</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2000</th>\n      <td>../input/covidpreprocesseddata/train_224x224-2...</td>\n      <td>Normal</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>2001 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Defining Hyper Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_WIDTH, IMAGE_HEIGTH = 224, 224\nBATCH_SIZE = 32\nBASE_LAYER = 744 # (block6m_add)\nINPUT_TENSOR = (224, 224, 3)\nOPT = Adam(learning_rate=1e-3)\nLOSS = 'categorical_crossentropy'\nFOLDS = 5\nEPOCHS = 10","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keras Data Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train data generator\ndatagen_ = ImageDataGenerator(rescale=1./255,\n                            zoom_range=0.2,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            validation_split=0.2)\n# test data generator\ntest_ = ImageDataGenerator(rescale=1./255)","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model: EfficientNetB7"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining model and compiling it.\ndef EffNetB7(input_tensor=INPUT_TENSOR, weights=None, trainable=BASE_LAYER, optimizer=OPT, loss=LOSS):\n    \n    base_model = efn.EfficientNetB7(weights=weights,\n                               input_shape=input_tensor,\n                               include_top=False)\n    \n\n    model_in = base_model.output\n    global_avg = GlobalAveragePooling2D()(model_in)\n    dense_5 = Dense(512, activation='relu')(global_avg)\n    final = Dense(3, activation='softmax')(dense_5)\n    model = Model(inputs=base_model.input, outputs=final)\n    \n    # training last layers\n    print('\\nFine-Tuning Model. Training last 2 blocks only...\\n')\n    for layer in model.layers[:trainable]:\n        layer.trainable = False\n        \n    for layer in model.layers[trainable:]:\n        layer.trainable = True\n    \n    # compiling model\n    print('\\nCompiling Model...\\n')\n    model.compile(optimizer = optimizer,\n              loss = loss,\n              metrics=['accuracy', 'AUC', Precision(), Recall()])\n    \n    return model","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"# callback function\ndef get_callbacks(model_name, monitor = 'val_loss'):\n    callbacks = []\n    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'{model_name}.h5',\n                                                         monitor = monitor,\n                                                         model = 'auto',\n                                                         save_best_only = True)\n    callbacks.append(model_checkpoint)\n    \n    return callbacks","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"120"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Training\n\n## Training On k-folds"},{"metadata":{"trusted":true},"cell_type":"code","source":"# saved models path\nmodel_path = '/kaggle/working/'","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting counter \ncount = 0\n\n# training for kfolds\nfor fold in range(FOLDS):\n\n    train_losses = []\n    train_accuracies = []\n    train_aucs = []\n    train_precisions = []\n    train_recalls = []\n\n    val_losses = []\n    val_accuracies = []\n    val_aucs = []\n    val_precisions = []\n    val_recalls = []\n    \n    df_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    df_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    \n    print(f'fold-{count+1}', len(df_train), len(df_valid))\n    \n    # Train and Validation\n    train_gen = datagen_.flow_from_dataframe(df_train,\n                                            x_col='path',\n                                            y_col='label',\n                                            target_size=(IMAGE_HEIGTH, IMAGE_WIDTH),\n                                            batch_size=BATCH_SIZE,\n                                            shuffle=True,\n                                            seed=2020,\n                                            class_mode='categorical')\n\n    val_gen = datagen_.flow_from_dataframe(df_valid,\n                                            x_col='path',\n                                            y_col='label',\n                                            target_size=(IMAGE_HEIGTH, IMAGE_WIDTH),\n                                            batch_size=BATCH_SIZE,\n                                            shuffle=True,\n                                            seed=2020,\n                                            class_mode='categorical')\n    \n    # model\n    model = EffNetB7(input_tensor=INPUT_TENSOR, weights='imagenet', trainable=BASE_LAYER, optimizer=OPT, loss=LOSS)\n    \n    # training\n    model.fit(train_gen, \n              validation_data=val_gen,\n              epochs=EPOCHS,\n              callbacks=get_callbacks(f'covid_base_model_{count+1}'))\n    \n    # Training Evaluation\n    print()\n    print('Evaluating on training data...')\n    train_loss, train_accuracy, train_auc, train_precision, train_recall = model.evaluate(train_gen)\n    \n    # Training Metrics\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n    train_aucs.append(train_auc)\n    train_precisions.append(train_precision)\n    train_recalls.append(train_recall)\n    \n    #Validation Evaluating\n    print()\n    print('Evaluating on validation data...')\n    model = load_model(os.path.join(model_path, f'covid_base_model_{count+1}.h5'))\n    val_loss, val_accuracy, val_auc, val_precision, val_recall = model.evaluate(val_gen)\n    \n    # Validation Metrics\n    val_losses.append(val_loss)\n    val_accuracies.append(val_accuracy)\n    val_aucs.append(val_auc)\n    val_precisions.append(val_precision)\n    val_recalls.append(val_recall)\n\n    print('##############################################################################')\n    print()\n    \n    count+=1","execution_count":17,"outputs":[{"output_type":"stream","text":"fold-1 1600 401\nFound 1600 validated image filenames belonging to 3 classes.\nFound 401 validated image filenames belonging to 3 classes.\nDownloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n258441216/258434480 [==============================] - 3s 0us/step\n\nFine-Tuning Model. Training last 2 blocks only...\n\n\nCompiling Model...\n\nEpoch 1/10\n50/50 [==============================] - 42s 845ms/step - loss: 1.0460 - accuracy: 0.5606 - auc: 0.7452 - precision: 0.5943 - recall: 0.4806 - val_loss: 1.0534 - val_accuracy: 0.5985 - val_auc: 0.7699 - val_precision: 0.6494 - val_recall: 0.5312\nEpoch 2/10\n50/50 [==============================] - 35s 701ms/step - loss: 0.7674 - accuracy: 0.7006 - auc: 0.8535 - precision: 0.7349 - recall: 0.6444 - val_loss: 0.9435 - val_accuracy: 0.6509 - val_auc: 0.8268 - val_precision: 0.6731 - val_recall: 0.6110\nEpoch 3/10\n50/50 [==============================] - 34s 679ms/step - loss: 0.6656 - accuracy: 0.7394 - auc: 0.8874 - precision: 0.7760 - recall: 0.6906 - val_loss: 0.7830 - val_accuracy: 0.7207 - val_auc: 0.8684 - val_precision: 0.7609 - val_recall: 0.6509\nEpoch 4/10\n50/50 [==============================] - 35s 701ms/step - loss: 0.6246 - accuracy: 0.7406 - auc: 0.8980 - precision: 0.7841 - recall: 0.6944 - val_loss: 0.5618 - val_accuracy: 0.7805 - val_auc: 0.9192 - val_precision: 0.8162 - val_recall: 0.7531\nEpoch 5/10\n50/50 [==============================] - 32s 639ms/step - loss: 0.5486 - accuracy: 0.7812 - auc: 0.9204 - precision: 0.8114 - recall: 0.7500 - val_loss: 0.5996 - val_accuracy: 0.7855 - val_auc: 0.9222 - val_precision: 0.8108 - val_recall: 0.7481\nEpoch 6/10\n50/50 [==============================] - 31s 626ms/step - loss: 0.5244 - accuracy: 0.7956 - auc: 0.9273 - precision: 0.8306 - recall: 0.7631 - val_loss: 0.5828 - val_accuracy: 0.7955 - val_auc: 0.9244 - val_precision: 0.8077 - val_recall: 0.7855\nEpoch 7/10\n50/50 [==============================] - 32s 639ms/step - loss: 0.4866 - accuracy: 0.8037 - auc: 0.9372 - precision: 0.8292 - recall: 0.7675 - val_loss: 0.5922 - val_accuracy: 0.7930 - val_auc: 0.9230 - val_precision: 0.8196 - val_recall: 0.7706\nEpoch 8/10\n50/50 [==============================] - 33s 667ms/step - loss: 0.4223 - accuracy: 0.8419 - auc: 0.9524 - precision: 0.8684 - recall: 0.8169 - val_loss: 0.4596 - val_accuracy: 0.8354 - val_auc: 0.9476 - val_precision: 0.8490 - val_recall: 0.8130\nEpoch 9/10\n50/50 [==============================] - 32s 644ms/step - loss: 0.4497 - accuracy: 0.8300 - auc: 0.9454 - precision: 0.8513 - recall: 0.8087 - val_loss: 0.5015 - val_accuracy: 0.8204 - val_auc: 0.9399 - val_precision: 0.8395 - val_recall: 0.7955\nEpoch 10/10\n50/50 [==============================] - 31s 619ms/step - loss: 0.4138 - accuracy: 0.8462 - auc: 0.9536 - precision: 0.8633 - recall: 0.8250 - val_loss: 0.4699 - val_accuracy: 0.8429 - val_auc: 0.9497 - val_precision: 0.8492 - val_recall: 0.8429\n\nEvaluating on training data...\n50/50 [==============================] - 24s 490ms/step - loss: 0.2319 - accuracy: 0.9175 - auc: 0.9843 - precision: 0.9235 - recall: 0.9125\n\nEvaluating on validation data...\n13/13 [==============================] - 5s 410ms/step - loss: 0.5068 - accuracy: 0.8429 - auc: 0.9432 - precision: 0.8656 - recall: 0.8354\n##############################################################################\n\nfold-2 1601 400\nFound 1601 validated image filenames belonging to 3 classes.\nFound 400 validated image filenames belonging to 3 classes.\n\nFine-Tuning Model. Training last 2 blocks only...\n\n\nCompiling Model...\n\nEpoch 1/10\n51/51 [==============================] - 39s 765ms/step - loss: 1.3742 - accuracy: 0.5478 - auc: 0.7139 - precision_1: 0.5787 - recall_1: 0.4547 - val_loss: 18.9712 - val_accuracy: 0.3475 - val_auc: 0.5232 - val_precision_1: 0.3475 - val_recall_1: 0.3475\nEpoch 2/10\n51/51 [==============================] - 35s 684ms/step - loss: 0.7421 - accuracy: 0.6790 - auc: 0.8522 - precision_1: 0.7336 - recall_1: 0.6002 - val_loss: 0.7280 - val_accuracy: 0.7350 - val_auc: 0.8917 - val_precision_1: 0.7769 - val_recall_1: 0.7050\nEpoch 3/10\n51/51 [==============================] - 35s 682ms/step - loss: 0.6585 - accuracy: 0.7408 - auc: 0.8865 - precision_1: 0.7881 - recall_1: 0.6646 - val_loss: 0.5583 - val_accuracy: 0.7900 - val_auc: 0.9189 - val_precision_1: 0.8254 - val_recall_1: 0.7325\nEpoch 4/10\n51/51 [==============================] - 34s 671ms/step - loss: 0.6076 - accuracy: 0.7514 - auc: 0.9023 - precision_1: 0.7829 - recall_1: 0.6958 - val_loss: 0.5498 - val_accuracy: 0.7800 - val_auc: 0.9208 - val_precision_1: 0.8011 - val_recall_1: 0.7250\nEpoch 5/10\n51/51 [==============================] - 34s 675ms/step - loss: 0.5730 - accuracy: 0.7720 - auc: 0.9147 - precision_1: 0.8122 - recall_1: 0.7214 - val_loss: 0.5490 - val_accuracy: 0.7925 - val_auc: 0.9239 - val_precision_1: 0.8143 - val_recall_1: 0.7675\nEpoch 6/10\n51/51 [==============================] - 34s 666ms/step - loss: 0.5220 - accuracy: 0.7908 - auc: 0.9273 - precision_1: 0.8146 - recall_1: 0.7601 - val_loss: 0.4514 - val_accuracy: 0.8425 - val_auc: 0.9487 - val_precision_1: 0.8597 - val_recall_1: 0.8275\nEpoch 7/10\n51/51 [==============================] - 32s 627ms/step - loss: 0.4622 - accuracy: 0.8339 - auc: 0.9430 - precision_1: 0.8598 - recall_1: 0.8007 - val_loss: 0.5103 - val_accuracy: 0.8050 - val_auc: 0.9318 - val_precision_1: 0.8259 - val_recall_1: 0.7825\nEpoch 8/10\n51/51 [==============================] - 35s 692ms/step - loss: 0.4591 - accuracy: 0.8176 - auc: 0.9442 - precision_1: 0.8367 - recall_1: 0.7870 - val_loss: 0.5010 - val_accuracy: 0.8100 - val_auc: 0.9354 - val_precision_1: 0.8149 - val_recall_1: 0.7925\nEpoch 9/10\n51/51 [==============================] - 79s 2s/step - loss: 0.4328 - accuracy: 0.8382 - auc: 0.9499 - precision_1: 0.8561 - recall_1: 0.8139 - val_loss: 0.4899 - val_accuracy: 0.8225 - val_auc: 0.9376 - val_precision_1: 0.8380 - val_recall_1: 0.8150\nEpoch 10/10\n51/51 [==============================] - 34s 663ms/step - loss: 0.4132 - accuracy: 0.8476 - auc: 0.9543 - precision_1: 0.8616 - recall_1: 0.8282 - val_loss: 0.4074 - val_accuracy: 0.8475 - val_auc: 0.9570 - val_precision_1: 0.8632 - val_recall_1: 0.8200\n\nEvaluating on training data...\n51/51 [==============================] - 25s 482ms/step - loss: 0.2357 - accuracy: 0.9176 - auc: 0.9848 - precision_1: 0.9285 - recall_1: 0.9088\n\nEvaluating on validation data...\n13/13 [==============================] - 5s 422ms/step - loss: 0.4382 - accuracy: 0.8375 - auc_1: 0.9515 - precision_1: 0.8416 - recall_1: 0.8100\n##############################################################################\n\nfold-3 1601 400\nFound 1601 validated image filenames belonging to 3 classes.\nFound 400 validated image filenames belonging to 3 classes.\n\nFine-Tuning Model. Training last 2 blocks only...\n\n\nCompiling Model...\n\nEpoch 1/10\n51/51 [==============================] - 39s 773ms/step - loss: 1.5025 - accuracy: 0.5197 - auc: 0.6939 - precision_2: 0.5502 - recall_2: 0.4041 - val_loss: 20.0555 - val_accuracy: 0.3775 - val_auc: 0.5499 - val_precision_2: 0.3788 - val_recall_2: 0.3750\nEpoch 2/10\n51/51 [==============================] - 35s 680ms/step - loss: 0.7742 - accuracy: 0.6602 - auc: 0.8385 - precision_2: 0.7347 - recall_2: 0.5621 - val_loss: 0.7445 - val_accuracy: 0.6775 - val_auc: 0.8543 - val_precision_2: 0.7155 - val_recall_2: 0.6100\nEpoch 3/10\n51/51 [==============================] - 35s 692ms/step - loss: 0.6952 - accuracy: 0.7308 - auc: 0.8727 - precision_2: 0.7773 - recall_2: 0.6452 - val_loss: 0.6412 - val_accuracy: 0.7525 - val_auc: 0.9014 - val_precision_2: 0.7989 - val_recall_2: 0.7150\nEpoch 4/10\n51/51 [==============================] - 32s 618ms/step - loss: 0.5995 - accuracy: 0.7626 - auc: 0.9036 - precision_2: 0.8018 - recall_2: 0.7102 - val_loss: 0.6910 - val_accuracy: 0.7525 - val_auc: 0.8941 - val_precision_2: 0.7885 - val_recall_2: 0.7175\nEpoch 5/10\n51/51 [==============================] - 35s 684ms/step - loss: 0.5755 - accuracy: 0.7826 - auc: 0.9115 - precision_2: 0.8096 - recall_2: 0.7358 - val_loss: 0.5468 - val_accuracy: 0.8100 - val_auc: 0.9287 - val_precision_2: 0.8386 - val_recall_2: 0.7925\n","name":"stdout"},{"output_type":"stream","text":"Epoch 6/10\n51/51 [==============================] - 35s 685ms/step - loss: 0.5376 - accuracy: 0.7845 - auc: 0.9227 - precision_2: 0.8128 - recall_2: 0.7514 - val_loss: 0.5363 - val_accuracy: 0.7925 - val_auc: 0.9261 - val_precision_2: 0.8288 - val_recall_2: 0.7625\nEpoch 7/10\n51/51 [==============================] - 35s 677ms/step - loss: 0.5036 - accuracy: 0.8114 - auc: 0.9323 - precision_2: 0.8360 - recall_2: 0.7833 - val_loss: 0.5082 - val_accuracy: 0.8025 - val_auc: 0.9360 - val_precision_2: 0.8329 - val_recall_2: 0.7725\nEpoch 8/10\n51/51 [==============================] - 35s 689ms/step - loss: 0.4704 - accuracy: 0.8126 - auc: 0.9406 - precision_2: 0.8399 - recall_2: 0.7895 - val_loss: 0.4646 - val_accuracy: 0.8350 - val_auc: 0.9438 - val_precision_2: 0.8864 - val_recall_2: 0.8000\nEpoch 9/10\n51/51 [==============================] - 31s 617ms/step - loss: 0.4317 - accuracy: 0.8382 - auc: 0.9502 - precision_2: 0.8641 - recall_2: 0.8145 - val_loss: 0.4795 - val_accuracy: 0.8200 - val_auc: 0.9420 - val_precision_2: 0.8403 - val_recall_2: 0.8025\nEpoch 10/10\n51/51 [==============================] - 32s 624ms/step - loss: 0.4247 - accuracy: 0.8301 - auc: 0.9515 - precision_2: 0.8575 - recall_2: 0.8082 - val_loss: 0.4955 - val_accuracy: 0.8275 - val_auc: 0.9426 - val_precision_2: 0.8500 - val_recall_2: 0.8075\n\nEvaluating on training data...\n51/51 [==============================] - 24s 462ms/step - loss: 0.2587 - accuracy: 0.9063 - auc: 0.9817 - precision_2: 0.9232 - recall_2: 0.8932\n\nEvaluating on validation data...\n13/13 [==============================] - 6s 440ms/step - loss: 0.4563 - accuracy: 0.8050 - auc_2: 0.9450 - precision_2: 0.8552 - recall_2: 0.7675\n##############################################################################\n\nfold-4 1601 400\nFound 1601 validated image filenames belonging to 3 classes.\nFound 400 validated image filenames belonging to 3 classes.\n\nFine-Tuning Model. Training last 2 blocks only...\n\n\nCompiling Model...\n\nEpoch 1/10\n51/51 [==============================] - 41s 805ms/step - loss: 2.1804 - accuracy: 0.4722 - auc: 0.6454 - precision_3: 0.4813 - recall_3: 0.4191 - val_loss: 11.1182 - val_accuracy: 0.3575 - val_auc: 0.5478 - val_precision_3: 0.3575 - val_recall_3: 0.3575\nEpoch 2/10\n51/51 [==============================] - 36s 705ms/step - loss: 0.8249 - accuracy: 0.6433 - auc: 0.8206 - precision_3: 0.7056 - recall_3: 0.4866 - val_loss: 0.8366 - val_accuracy: 0.6750 - val_auc: 0.8375 - val_precision_3: 0.6883 - val_recall_3: 0.6350\nEpoch 3/10\n51/51 [==============================] - 35s 694ms/step - loss: 0.6793 - accuracy: 0.7258 - auc: 0.8765 - precision_3: 0.7650 - recall_3: 0.6465 - val_loss: 0.6784 - val_accuracy: 0.7275 - val_auc: 0.8878 - val_precision_3: 0.7572 - val_recall_3: 0.6550\nEpoch 4/10\n51/51 [==============================] - 37s 720ms/step - loss: 0.6263 - accuracy: 0.7420 - auc: 0.8973 - precision_3: 0.7836 - recall_3: 0.6964 - val_loss: 0.5532 - val_accuracy: 0.8075 - val_auc: 0.9208 - val_precision_3: 0.8375 - val_recall_3: 0.7600\nEpoch 5/10\n51/51 [==============================] - 32s 632ms/step - loss: 0.5903 - accuracy: 0.7608 - auc: 0.9085 - precision_3: 0.7965 - recall_3: 0.7039 - val_loss: 0.5882 - val_accuracy: 0.7675 - val_auc: 0.9122 - val_precision_3: 0.7921 - val_recall_3: 0.7525\nEpoch 6/10\n51/51 [==============================] - 33s 644ms/step - loss: 0.5481 - accuracy: 0.7751 - auc: 0.9205 - precision_3: 0.8174 - recall_3: 0.7439 - val_loss: 0.6735 - val_accuracy: 0.7850 - val_auc: 0.9105 - val_precision_3: 0.8102 - val_recall_3: 0.7575\nEpoch 7/10\n51/51 [==============================] - 32s 635ms/step - loss: 0.4787 - accuracy: 0.8182 - auc: 0.9391 - precision_3: 0.8460 - recall_3: 0.7758 - val_loss: 0.6187 - val_accuracy: 0.8125 - val_auc: 0.9221 - val_precision_3: 0.8285 - val_recall_3: 0.7850\nEpoch 8/10\n51/51 [==============================] - 36s 716ms/step - loss: 0.4982 - accuracy: 0.8095 - auc: 0.9351 - precision_3: 0.8361 - recall_3: 0.7776 - val_loss: 0.5383 - val_accuracy: 0.8125 - val_auc: 0.9336 - val_precision_3: 0.8282 - val_recall_3: 0.8075\nEpoch 9/10\n51/51 [==============================] - 38s 737ms/step - loss: 0.4531 - accuracy: 0.8282 - auc: 0.9449 - precision_3: 0.8532 - recall_3: 0.8020 - val_loss: 0.4659 - val_accuracy: 0.8400 - val_auc: 0.9441 - val_precision_3: 0.8557 - val_recall_3: 0.8300\nEpoch 10/10\n51/51 [==============================] - 36s 710ms/step - loss: 0.4115 - accuracy: 0.8401 - auc: 0.9547 - precision_3: 0.8614 - recall_3: 0.8189 - val_loss: 0.4493 - val_accuracy: 0.8575 - val_auc: 0.9496 - val_precision_3: 0.8711 - val_recall_3: 0.8450\n\nEvaluating on training data...\n51/51 [==============================] - 26s 511ms/step - loss: 0.2305 - accuracy: 0.9119 - auc: 0.9855 - precision_3: 0.9281 - recall_3: 0.9026\n\nEvaluating on validation data...\n13/13 [==============================] - 6s 429ms/step - loss: 0.4547 - accuracy: 0.8375 - auc_3: 0.9492 - precision_3: 0.8448 - recall_3: 0.8300\n##############################################################################\n\nfold-5 1601 400\nFound 1601 validated image filenames belonging to 3 classes.\nFound 400 validated image filenames belonging to 3 classes.\n\nFine-Tuning Model. Training last 2 blocks only...\n\n\nCompiling Model...\n\nEpoch 1/10\n51/51 [==============================] - 42s 832ms/step - loss: 1.7841 - accuracy: 0.5284 - auc: 0.7038 - precision_4: 0.5466 - recall_4: 0.4722 - val_loss: 5.3929 - val_accuracy: 0.4100 - val_auc: 0.5982 - val_precision_4: 0.4110 - val_recall_4: 0.4100\nEpoch 2/10\n51/51 [==============================] - 41s 804ms/step - loss: 0.7659 - accuracy: 0.6864 - auc: 0.8464 - precision_4: 0.7486 - recall_4: 0.5840 - val_loss: 0.8429 - val_accuracy: 0.6725 - val_auc: 0.8478 - val_precision_4: 0.7041 - val_recall_4: 0.6425\nEpoch 3/10\n51/51 [==============================] - 41s 797ms/step - loss: 0.6553 - accuracy: 0.7252 - auc: 0.8859 - precision_4: 0.7781 - recall_4: 0.6658 - val_loss: 0.6670 - val_accuracy: 0.7525 - val_auc: 0.8937 - val_precision_4: 0.8023 - val_recall_4: 0.7100\nEpoch 4/10\n51/51 [==============================] - 36s 705ms/step - loss: 0.5797 - accuracy: 0.7695 - auc: 0.9119 - precision_4: 0.8172 - recall_4: 0.7233 - val_loss: 0.6738 - val_accuracy: 0.7375 - val_auc: 0.8966 - val_precision_4: 0.7772 - val_recall_4: 0.7150\nEpoch 5/10\n51/51 [==============================] - 42s 822ms/step - loss: 0.5681 - accuracy: 0.7795 - auc: 0.9164 - precision_4: 0.8180 - recall_4: 0.7383 - val_loss: 0.5639 - val_accuracy: 0.8000 - val_auc: 0.9192 - val_precision_4: 0.8122 - val_recall_4: 0.7675\nEpoch 6/10\n51/51 [==============================] - 43s 834ms/step - loss: 0.5515 - accuracy: 0.7789 - auc: 0.9194 - precision_4: 0.8082 - recall_4: 0.7420 - val_loss: 0.5310 - val_accuracy: 0.7925 - val_auc: 0.9295 - val_precision_4: 0.8218 - val_recall_4: 0.7725\nEpoch 7/10\n51/51 [==============================] - 35s 688ms/step - loss: 0.4978 - accuracy: 0.8032 - auc: 0.9341 - precision_4: 0.8396 - recall_4: 0.7683 - val_loss: 0.5325 - val_accuracy: 0.8175 - val_auc: 0.9315 - val_precision_4: 0.8307 - val_recall_4: 0.7975\nEpoch 8/10\n51/51 [==============================] - 34s 671ms/step - loss: 0.4715 - accuracy: 0.8232 - auc: 0.9408 - precision_4: 0.8481 - recall_4: 0.7883 - val_loss: 0.5352 - val_accuracy: 0.8175 - val_auc: 0.9310 - val_precision_4: 0.8417 - val_recall_4: 0.7975\nEpoch 9/10\n51/51 [==============================] - 35s 694ms/step - loss: 0.4576 - accuracy: 0.8282 - auc: 0.9443 - precision_4: 0.8566 - recall_4: 0.8020 - val_loss: 0.5602 - val_accuracy: 0.8100 - val_auc: 0.9270 - val_precision_4: 0.8281 - val_recall_4: 0.7950\nEpoch 10/10\n51/51 [==============================] - 42s 815ms/step - loss: 0.4287 - accuracy: 0.8345 - auc: 0.9509 - precision_4: 0.8567 - recall_4: 0.8139 - val_loss: 0.5106 - val_accuracy: 0.8100 - val_auc: 0.9354 - val_precision_4: 0.8260 - val_recall_4: 0.7950\n\nEvaluating on training data...\n51/51 [==============================] - 26s 510ms/step - loss: 0.2946 - accuracy: 0.8982 - auc: 0.9770 - precision_4: 0.9146 - recall_4: 0.8832\n\nEvaluating on validation data...\n","name":"stdout"},{"output_type":"stream","text":"13/13 [==============================] - 7s 537ms/step - loss: 0.5484 - accuracy: 0.7925 - auc_4: 0.9281 - precision_4: 0.8130 - recall_4: 0.7825\n##############################################################################\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting index and layer name\nfor index, layer in enumerate(model.layers):\n    print(index, layer.name)","execution_count":18,"outputs":[{"output_type":"stream","text":"0 input_5\n1 stem_conv\n2 stem_bn\n3 stem_activation\n4 block1a_dwconv\n5 block1a_bn\n6 block1a_activation\n7 block1a_se_squeeze\n8 block1a_se_reshape\n9 block1a_se_reduce\n10 block1a_se_expand\n11 block1a_se_excite\n12 block1a_project_conv\n13 block1a_project_bn\n14 block1b_dwconv\n15 block1b_bn\n16 block1b_activation\n17 block1b_se_squeeze\n18 block1b_se_reshape\n19 block1b_se_reduce\n20 block1b_se_expand\n21 block1b_se_excite\n22 block1b_project_conv\n23 block1b_project_bn\n24 block1b_drop\n25 block1b_add\n26 block1c_dwconv\n27 block1c_bn\n28 block1c_activation\n29 block1c_se_squeeze\n30 block1c_se_reshape\n31 block1c_se_reduce\n32 block1c_se_expand\n33 block1c_se_excite\n34 block1c_project_conv\n35 block1c_project_bn\n36 block1c_drop\n37 block1c_add\n38 block1d_dwconv\n39 block1d_bn\n40 block1d_activation\n41 block1d_se_squeeze\n42 block1d_se_reshape\n43 block1d_se_reduce\n44 block1d_se_expand\n45 block1d_se_excite\n46 block1d_project_conv\n47 block1d_project_bn\n48 block1d_drop\n49 block1d_add\n50 block2a_expand_conv\n51 block2a_expand_bn\n52 block2a_expand_activation\n53 block2a_dwconv\n54 block2a_bn\n55 block2a_activation\n56 block2a_se_squeeze\n57 block2a_se_reshape\n58 block2a_se_reduce\n59 block2a_se_expand\n60 block2a_se_excite\n61 block2a_project_conv\n62 block2a_project_bn\n63 block2b_expand_conv\n64 block2b_expand_bn\n65 block2b_expand_activation\n66 block2b_dwconv\n67 block2b_bn\n68 block2b_activation\n69 block2b_se_squeeze\n70 block2b_se_reshape\n71 block2b_se_reduce\n72 block2b_se_expand\n73 block2b_se_excite\n74 block2b_project_conv\n75 block2b_project_bn\n76 block2b_drop\n77 block2b_add\n78 block2c_expand_conv\n79 block2c_expand_bn\n80 block2c_expand_activation\n81 block2c_dwconv\n82 block2c_bn\n83 block2c_activation\n84 block2c_se_squeeze\n85 block2c_se_reshape\n86 block2c_se_reduce\n87 block2c_se_expand\n88 block2c_se_excite\n89 block2c_project_conv\n90 block2c_project_bn\n91 block2c_drop\n92 block2c_add\n93 block2d_expand_conv\n94 block2d_expand_bn\n95 block2d_expand_activation\n96 block2d_dwconv\n97 block2d_bn\n98 block2d_activation\n99 block2d_se_squeeze\n100 block2d_se_reshape\n101 block2d_se_reduce\n102 block2d_se_expand\n103 block2d_se_excite\n104 block2d_project_conv\n105 block2d_project_bn\n106 block2d_drop\n107 block2d_add\n108 block2e_expand_conv\n109 block2e_expand_bn\n110 block2e_expand_activation\n111 block2e_dwconv\n112 block2e_bn\n113 block2e_activation\n114 block2e_se_squeeze\n115 block2e_se_reshape\n116 block2e_se_reduce\n117 block2e_se_expand\n118 block2e_se_excite\n119 block2e_project_conv\n120 block2e_project_bn\n121 block2e_drop\n122 block2e_add\n123 block2f_expand_conv\n124 block2f_expand_bn\n125 block2f_expand_activation\n126 block2f_dwconv\n127 block2f_bn\n128 block2f_activation\n129 block2f_se_squeeze\n130 block2f_se_reshape\n131 block2f_se_reduce\n132 block2f_se_expand\n133 block2f_se_excite\n134 block2f_project_conv\n135 block2f_project_bn\n136 block2f_drop\n137 block2f_add\n138 block2g_expand_conv\n139 block2g_expand_bn\n140 block2g_expand_activation\n141 block2g_dwconv\n142 block2g_bn\n143 block2g_activation\n144 block2g_se_squeeze\n145 block2g_se_reshape\n146 block2g_se_reduce\n147 block2g_se_expand\n148 block2g_se_excite\n149 block2g_project_conv\n150 block2g_project_bn\n151 block2g_drop\n152 block2g_add\n153 block3a_expand_conv\n154 block3a_expand_bn\n155 block3a_expand_activation\n156 block3a_dwconv\n157 block3a_bn\n158 block3a_activation\n159 block3a_se_squeeze\n160 block3a_se_reshape\n161 block3a_se_reduce\n162 block3a_se_expand\n163 block3a_se_excite\n164 block3a_project_conv\n165 block3a_project_bn\n166 block3b_expand_conv\n167 block3b_expand_bn\n168 block3b_expand_activation\n169 block3b_dwconv\n170 block3b_bn\n171 block3b_activation\n172 block3b_se_squeeze\n173 block3b_se_reshape\n174 block3b_se_reduce\n175 block3b_se_expand\n176 block3b_se_excite\n177 block3b_project_conv\n178 block3b_project_bn\n179 block3b_drop\n180 block3b_add\n181 block3c_expand_conv\n182 block3c_expand_bn\n183 block3c_expand_activation\n184 block3c_dwconv\n185 block3c_bn\n186 block3c_activation\n187 block3c_se_squeeze\n188 block3c_se_reshape\n189 block3c_se_reduce\n190 block3c_se_expand\n191 block3c_se_excite\n192 block3c_project_conv\n193 block3c_project_bn\n194 block3c_drop\n195 block3c_add\n196 block3d_expand_conv\n197 block3d_expand_bn\n198 block3d_expand_activation\n199 block3d_dwconv\n200 block3d_bn\n201 block3d_activation\n202 block3d_se_squeeze\n203 block3d_se_reshape\n204 block3d_se_reduce\n205 block3d_se_expand\n206 block3d_se_excite\n207 block3d_project_conv\n208 block3d_project_bn\n209 block3d_drop\n210 block3d_add\n211 block3e_expand_conv\n212 block3e_expand_bn\n213 block3e_expand_activation\n214 block3e_dwconv\n215 block3e_bn\n216 block3e_activation\n217 block3e_se_squeeze\n218 block3e_se_reshape\n219 block3e_se_reduce\n220 block3e_se_expand\n221 block3e_se_excite\n222 block3e_project_conv\n223 block3e_project_bn\n224 block3e_drop\n225 block3e_add\n226 block3f_expand_conv\n227 block3f_expand_bn\n228 block3f_expand_activation\n229 block3f_dwconv\n230 block3f_bn\n231 block3f_activation\n232 block3f_se_squeeze\n233 block3f_se_reshape\n234 block3f_se_reduce\n235 block3f_se_expand\n236 block3f_se_excite\n237 block3f_project_conv\n238 block3f_project_bn\n239 block3f_drop\n240 block3f_add\n241 block3g_expand_conv\n242 block3g_expand_bn\n243 block3g_expand_activation\n244 block3g_dwconv\n245 block3g_bn\n246 block3g_activation\n247 block3g_se_squeeze\n248 block3g_se_reshape\n249 block3g_se_reduce\n250 block3g_se_expand\n251 block3g_se_excite\n252 block3g_project_conv\n253 block3g_project_bn\n254 block3g_drop\n255 block3g_add\n256 block4a_expand_conv\n257 block4a_expand_bn\n258 block4a_expand_activation\n259 block4a_dwconv\n260 block4a_bn\n261 block4a_activation\n262 block4a_se_squeeze\n263 block4a_se_reshape\n264 block4a_se_reduce\n265 block4a_se_expand\n266 block4a_se_excite\n267 block4a_project_conv\n268 block4a_project_bn\n269 block4b_expand_conv\n270 block4b_expand_bn\n271 block4b_expand_activation\n272 block4b_dwconv\n273 block4b_bn\n274 block4b_activation\n275 block4b_se_squeeze\n276 block4b_se_reshape\n277 block4b_se_reduce\n278 block4b_se_expand\n279 block4b_se_excite\n280 block4b_project_conv\n281 block4b_project_bn\n282 block4b_drop\n283 block4b_add\n284 block4c_expand_conv\n285 block4c_expand_bn\n286 block4c_expand_activation\n287 block4c_dwconv\n288 block4c_bn\n289 block4c_activation\n290 block4c_se_squeeze\n291 block4c_se_reshape\n292 block4c_se_reduce\n293 block4c_se_expand\n294 block4c_se_excite\n295 block4c_project_conv\n296 block4c_project_bn\n297 block4c_drop\n298 block4c_add\n299 block4d_expand_conv\n300 block4d_expand_bn\n301 block4d_expand_activation\n302 block4d_dwconv\n303 block4d_bn\n304 block4d_activation\n305 block4d_se_squeeze\n306 block4d_se_reshape\n307 block4d_se_reduce\n308 block4d_se_expand\n309 block4d_se_excite\n310 block4d_project_conv\n311 block4d_project_bn\n312 block4d_drop\n313 block4d_add\n314 block4e_expand_conv\n315 block4e_expand_bn\n316 block4e_expand_activation\n317 block4e_dwconv\n318 block4e_bn\n319 block4e_activation\n320 block4e_se_squeeze\n321 block4e_se_reshape\n322 block4e_se_reduce\n323 block4e_se_expand\n324 block4e_se_excite\n325 block4e_project_conv\n326 block4e_project_bn\n327 block4e_drop\n328 block4e_add\n329 block4f_expand_conv\n330 block4f_expand_bn\n331 block4f_expand_activation\n332 block4f_dwconv\n333 block4f_bn\n334 block4f_activation\n335 block4f_se_squeeze\n336 block4f_se_reshape\n337 block4f_se_reduce\n338 block4f_se_expand\n339 block4f_se_excite\n340 block4f_project_conv\n341 block4f_project_bn\n342 block4f_drop\n343 block4f_add\n344 block4g_expand_conv\n345 block4g_expand_bn\n346 block4g_expand_activation\n347 block4g_dwconv\n348 block4g_bn\n349 block4g_activation\n350 block4g_se_squeeze\n351 block4g_se_reshape\n352 block4g_se_reduce\n353 block4g_se_expand\n354 block4g_se_excite\n355 block4g_project_conv\n356 block4g_project_bn\n357 block4g_drop\n358 block4g_add\n359 block4h_expand_conv\n360 block4h_expand_bn\n361 block4h_expand_activation\n362 block4h_dwconv\n363 block4h_bn\n364 block4h_activation\n365 block4h_se_squeeze\n366 block4h_se_reshape\n367 block4h_se_reduce\n368 block4h_se_expand\n369 block4h_se_excite\n370 block4h_project_conv\n371 block4h_project_bn\n372 block4h_drop\n373 block4h_add\n374 block4i_expand_conv\n375 block4i_expand_bn\n376 block4i_expand_activation\n377 block4i_dwconv\n378 block4i_bn\n379 block4i_activation\n380 block4i_se_squeeze\n381 block4i_se_reshape\n382 block4i_se_reduce\n383 block4i_se_expand\n384 block4i_se_excite\n385 block4i_project_conv\n386 block4i_project_bn\n387 block4i_drop\n388 block4i_add\n389 block4j_expand_conv\n390 block4j_expand_bn\n391 block4j_expand_activation\n392 block4j_dwconv\n393 block4j_bn\n394 block4j_activation\n395 block4j_se_squeeze\n396 block4j_se_reshape\n397 block4j_se_reduce\n398 block4j_se_expand\n399 block4j_se_excite\n400 block4j_project_conv\n401 block4j_project_bn\n402 block4j_drop\n403 block4j_add\n404 block5a_expand_conv\n405 block5a_expand_bn\n406 block5a_expand_activation\n407 block5a_dwconv\n408 block5a_bn\n409 block5a_activation\n410 block5a_se_squeeze\n411 block5a_se_reshape\n412 block5a_se_reduce\n413 block5a_se_expand\n414 block5a_se_excite\n415 block5a_project_conv\n416 block5a_project_bn\n417 block5b_expand_conv\n418 block5b_expand_bn\n419 block5b_expand_activation\n420 block5b_dwconv\n421 block5b_bn\n422 block5b_activation\n423 block5b_se_squeeze\n424 block5b_se_reshape\n425 block5b_se_reduce\n426 block5b_se_expand\n427 block5b_se_excite\n428 block5b_project_conv\n429 block5b_project_bn\n430 block5b_drop\n431 block5b_add\n432 block5c_expand_conv\n433 block5c_expand_bn\n434 block5c_expand_activation\n435 block5c_dwconv\n436 block5c_bn\n437 block5c_activation\n438 block5c_se_squeeze\n439 block5c_se_reshape\n440 block5c_se_reduce\n441 block5c_se_expand\n442 block5c_se_excite\n443 block5c_project_conv\n444 block5c_project_bn\n445 block5c_drop\n446 block5c_add\n447 block5d_expand_conv\n448 block5d_expand_bn\n449 block5d_expand_activation\n450 block5d_dwconv\n451 block5d_bn\n452 block5d_activation\n453 block5d_se_squeeze\n454 block5d_se_reshape\n455 block5d_se_reduce\n456 block5d_se_expand\n457 block5d_se_excite\n458 block5d_project_conv\n459 block5d_project_bn\n460 block5d_drop\n461 block5d_add\n462 block5e_expand_conv\n463 block5e_expand_bn\n464 block5e_expand_activation\n465 block5e_dwconv\n466 block5e_bn\n467 block5e_activation\n468 block5e_se_squeeze\n469 block5e_se_reshape\n470 block5e_se_reduce\n471 block5e_se_expand\n472 block5e_se_excite\n473 block5e_project_conv\n474 block5e_project_bn\n475 block5e_drop\n476 block5e_add\n477 block5f_expand_conv\n478 block5f_expand_bn\n479 block5f_expand_activation\n480 block5f_dwconv\n481 block5f_bn\n482 block5f_activation\n483 block5f_se_squeeze\n484 block5f_se_reshape\n485 block5f_se_reduce\n486 block5f_se_expand\n487 block5f_se_excite\n488 block5f_project_conv\n489 block5f_project_bn\n490 block5f_drop\n491 block5f_add\n492 block5g_expand_conv\n493 block5g_expand_bn\n494 block5g_expand_activation\n495 block5g_dwconv\n496 block5g_bn\n497 block5g_activation\n498 block5g_se_squeeze\n499 block5g_se_reshape\n500 block5g_se_reduce\n501 block5g_se_expand\n502 block5g_se_excite\n503 block5g_project_conv\n504 block5g_project_bn\n505 block5g_drop\n506 block5g_add\n507 block5h_expand_conv\n508 block5h_expand_bn\n509 block5h_expand_activation\n510 block5h_dwconv\n511 block5h_bn\n512 block5h_activation\n513 block5h_se_squeeze\n514 block5h_se_reshape\n515 block5h_se_reduce\n516 block5h_se_expand\n517 block5h_se_excite\n518 block5h_project_conv\n519 block5h_project_bn\n520 block5h_drop\n521 block5h_add\n522 block5i_expand_conv\n523 block5i_expand_bn\n524 block5i_expand_activation\n525 block5i_dwconv\n526 block5i_bn\n527 block5i_activation\n528 block5i_se_squeeze\n529 block5i_se_reshape\n530 block5i_se_reduce\n531 block5i_se_expand\n532 block5i_se_excite\n533 block5i_project_conv\n534 block5i_project_bn\n535 block5i_drop\n536 block5i_add\n537 block5j_expand_conv\n538 block5j_expand_bn\n539 block5j_expand_activation\n540 block5j_dwconv\n541 block5j_bn\n542 block5j_activation\n543 block5j_se_squeeze\n544 block5j_se_reshape\n545 block5j_se_reduce\n546 block5j_se_expand\n547 block5j_se_excite\n548 block5j_project_conv\n549 block5j_project_bn\n550 block5j_drop\n551 block5j_add\n552 block6a_expand_conv\n553 block6a_expand_bn\n554 block6a_expand_activation\n555 block6a_dwconv\n556 block6a_bn\n557 block6a_activation\n558 block6a_se_squeeze\n559 block6a_se_reshape\n560 block6a_se_reduce\n561 block6a_se_expand\n562 block6a_se_excite\n563 block6a_project_conv\n564 block6a_project_bn\n565 block6b_expand_conv\n566 block6b_expand_bn\n567 block6b_expand_activation\n568 block6b_dwconv\n569 block6b_bn\n570 block6b_activation\n571 block6b_se_squeeze\n572 block6b_se_reshape\n573 block6b_se_reduce\n574 block6b_se_expand\n575 block6b_se_excite\n576 block6b_project_conv\n577 block6b_project_bn\n578 block6b_drop\n579 block6b_add\n580 block6c_expand_conv\n581 block6c_expand_bn\n582 block6c_expand_activation\n583 block6c_dwconv\n584 block6c_bn\n585 block6c_activation\n586 block6c_se_squeeze\n587 block6c_se_reshape\n588 block6c_se_reduce\n589 block6c_se_expand\n590 block6c_se_excite\n591 block6c_project_conv\n592 block6c_project_bn\n593 block6c_drop\n594 block6c_add\n595 block6d_expand_conv\n596 block6d_expand_bn\n597 block6d_expand_activation\n598 block6d_dwconv\n599 block6d_bn\n600 block6d_activation\n601 block6d_se_squeeze\n602 block6d_se_reshape\n603 block6d_se_reduce\n604 block6d_se_expand\n605 block6d_se_excite\n606 block6d_project_conv\n607 block6d_project_bn\n608 block6d_drop\n609 block6d_add\n610 block6e_expand_conv\n611 block6e_expand_bn\n612 block6e_expand_activation\n613 block6e_dwconv\n614 block6e_bn\n615 block6e_activation\n616 block6e_se_squeeze\n617 block6e_se_reshape\n618 block6e_se_reduce\n619 block6e_se_expand\n620 block6e_se_excite\n621 block6e_project_conv\n622 block6e_project_bn\n623 block6e_drop\n624 block6e_add\n625 block6f_expand_conv\n626 block6f_expand_bn\n627 block6f_expand_activation\n628 block6f_dwconv\n629 block6f_bn\n630 block6f_activation\n631 block6f_se_squeeze\n632 block6f_se_reshape\n633 block6f_se_reduce\n634 block6f_se_expand\n635 block6f_se_excite\n636 block6f_project_conv\n637 block6f_project_bn\n638 block6f_drop\n639 block6f_add\n640 block6g_expand_conv\n641 block6g_expand_bn\n642 block6g_expand_activation\n643 block6g_dwconv\n644 block6g_bn\n645 block6g_activation\n646 block6g_se_squeeze\n647 block6g_se_reshape\n648 block6g_se_reduce\n649 block6g_se_expand\n650 block6g_se_excite\n651 block6g_project_conv\n652 block6g_project_bn\n653 block6g_drop\n654 block6g_add\n655 block6h_expand_conv\n656 block6h_expand_bn\n657 block6h_expand_activation\n658 block6h_dwconv\n659 block6h_bn\n660 block6h_activation\n661 block6h_se_squeeze\n662 block6h_se_reshape\n663 block6h_se_reduce\n664 block6h_se_expand\n665 block6h_se_excite\n666 block6h_project_conv\n667 block6h_project_bn\n668 block6h_drop\n669 block6h_add\n670 block6i_expand_conv\n671 block6i_expand_bn\n672 block6i_expand_activation\n673 block6i_dwconv\n674 block6i_bn\n675 block6i_activation\n676 block6i_se_squeeze\n677 block6i_se_reshape\n678 block6i_se_reduce\n679 block6i_se_expand\n680 block6i_se_excite\n681 block6i_project_conv\n682 block6i_project_bn\n683 block6i_drop\n684 block6i_add\n685 block6j_expand_conv\n686 block6j_expand_bn\n687 block6j_expand_activation\n688 block6j_dwconv\n689 block6j_bn\n690 block6j_activation\n691 block6j_se_squeeze\n692 block6j_se_reshape\n693 block6j_se_reduce\n694 block6j_se_expand\n695 block6j_se_excite\n696 block6j_project_conv\n697 block6j_project_bn\n698 block6j_drop\n699 block6j_add\n700 block6k_expand_conv\n701 block6k_expand_bn\n702 block6k_expand_activation\n703 block6k_dwconv\n704 block6k_bn\n705 block6k_activation\n706 block6k_se_squeeze\n707 block6k_se_reshape\n708 block6k_se_reduce\n709 block6k_se_expand\n710 block6k_se_excite\n711 block6k_project_conv\n712 block6k_project_bn\n713 block6k_drop\n714 block6k_add\n715 block6l_expand_conv\n716 block6l_expand_bn\n717 block6l_expand_activation\n718 block6l_dwconv\n719 block6l_bn\n720 block6l_activation\n721 block6l_se_squeeze\n722 block6l_se_reshape\n723 block6l_se_reduce\n724 block6l_se_expand\n725 block6l_se_excite\n726 block6l_project_conv\n727 block6l_project_bn\n728 block6l_drop\n729 block6l_add\n730 block6m_expand_conv\n731 block6m_expand_bn\n732 block6m_expand_activation\n733 block6m_dwconv\n734 block6m_bn\n735 block6m_activation\n736 block6m_se_squeeze\n737 block6m_se_reshape\n738 block6m_se_reduce\n739 block6m_se_expand\n740 block6m_se_excite\n741 block6m_project_conv\n742 block6m_project_bn\n743 block6m_drop\n744 block6m_add\n745 block7a_expand_conv\n746 block7a_expand_bn\n747 block7a_expand_activation\n748 block7a_dwconv\n749 block7a_bn\n750 block7a_activation\n751 block7a_se_squeeze\n752 block7a_se_reshape\n753 block7a_se_reduce\n754 block7a_se_expand\n755 block7a_se_excite\n756 block7a_project_conv\n757 block7a_project_bn\n758 block7b_expand_conv\n759 block7b_expand_bn\n760 block7b_expand_activation\n761 block7b_dwconv\n762 block7b_bn\n763 block7b_activation\n764 block7b_se_squeeze\n765 block7b_se_reshape\n766 block7b_se_reduce\n767 block7b_se_expand\n768 block7b_se_excite\n769 block7b_project_conv\n770 block7b_project_bn\n771 block7b_drop\n772 block7b_add\n773 block7c_expand_conv\n774 block7c_expand_bn\n775 block7c_expand_activation\n776 block7c_dwconv\n777 block7c_bn\n778 block7c_activation\n779 block7c_se_squeeze\n780 block7c_se_reshape\n781 block7c_se_reduce\n782 block7c_se_expand\n783 block7c_se_excite\n784 block7c_project_conv\n785 block7c_project_bn\n786 block7c_drop\n787 block7c_add\n788 block7d_expand_conv\n789 block7d_expand_bn\n790 block7d_expand_activation\n791 block7d_dwconv\n792 block7d_bn\n793 block7d_activation\n794 block7d_se_squeeze\n795 block7d_se_reshape\n796 block7d_se_reduce\n797 block7d_se_expand\n798 block7d_se_excite\n799 block7d_project_conv\n800 block7d_project_bn\n801 block7d_drop\n802 block7d_add\n803 top_conv\n804 top_bn\n805 top_activation\n806 global_average_pooling2d_4\n807 dense_8\n808 dense_9\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Training Full Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data generator for training model on full dataset\nfull_gen = datagen_.flow_from_dataframe(train_data,\n                                        x_col='path',\n                                        y_col='label',\n                                        target_size=(IMAGE_HEIGTH, IMAGE_WIDTH),\n                                        batch_size=BATCH_SIZE,\n                                        shuffle=True,\n                                        seed=2020,\n                                        class_mode='categorical')\n\n# model\nmodel = EffNetB7(input_tensor=INPUT_TENSOR, weights='imagenet', trainable=BASE_LAYER, optimizer=OPT, loss=LOSS)\n\n# training model\nprint('\\nTraining on full dataset...')\nhistory = model.fit(full_gen,\n                    epochs = 50,\n                    callbacks = get_callbacks(f'covid_base_model_fulldata'))","execution_count":19,"outputs":[{"output_type":"stream","text":"Found 2001 validated image filenames belonging to 3 classes.\n\nFine-Tuning Model. Training last 2 blocks only...\n\n\nCompiling Model...\n\n\nTraining on full dataset...\nEpoch 1/50\n63/63 [==============================] - 35s 551ms/step - loss: 1.6176 - accuracy: 0.5292 - auc: 0.7067 - precision_5: 0.5602 - recall_5: 0.4653\nEpoch 2/50\n63/63 [==============================] - 34s 538ms/step - loss: 0.7679 - accuracy: 0.6597 - auc: 0.8407 - precision_5: 0.7217 - recall_5: 0.5662\nEpoch 3/50\n63/63 [==============================] - 34s 547ms/step - loss: 0.6258 - accuracy: 0.7406 - auc: 0.8959 - precision_5: 0.7828 - recall_5: 0.6717\nEpoch 4/50\n63/63 [==============================] - 34s 540ms/step - loss: 0.6243 - accuracy: 0.7456 - auc: 0.8968 - precision_5: 0.7809 - recall_5: 0.6912\nEpoch 5/50\n63/63 [==============================] - 34s 540ms/step - loss: 0.5508 - accuracy: 0.7896 - auc: 0.9196 - precision_5: 0.8202 - recall_5: 0.7476\nEpoch 6/50\n63/63 [==============================] - 34s 545ms/step - loss: 0.4982 - accuracy: 0.8021 - auc: 0.9334 - precision_5: 0.8248 - recall_5: 0.7691\nEpoch 7/50\n63/63 [==============================] - 34s 535ms/step - loss: 0.4605 - accuracy: 0.8336 - auc: 0.9440 - precision_5: 0.8537 - recall_5: 0.8021\nEpoch 8/50\n63/63 [==============================] - 35s 548ms/step - loss: 0.4576 - accuracy: 0.8311 - auc: 0.9435 - precision_5: 0.8516 - recall_5: 0.8056\nEpoch 9/50\n63/63 [==============================] - 34s 535ms/step - loss: 0.4323 - accuracy: 0.8431 - auc: 0.9496 - precision_5: 0.8596 - recall_5: 0.8141\nEpoch 10/50\n63/63 [==============================] - 35s 550ms/step - loss: 0.4155 - accuracy: 0.8411 - auc: 0.9533 - precision_5: 0.8612 - recall_5: 0.8216\nEpoch 11/50\n63/63 [==============================] - 34s 544ms/step - loss: 0.4047 - accuracy: 0.8491 - auc: 0.9553 - precision_5: 0.8707 - recall_5: 0.8316\nEpoch 12/50\n63/63 [==============================] - 34s 540ms/step - loss: 0.3501 - accuracy: 0.8676 - auc: 0.9660 - precision_5: 0.8807 - recall_5: 0.8521\nEpoch 13/50\n63/63 [==============================] - 35s 550ms/step - loss: 0.3678 - accuracy: 0.8586 - auc: 0.9633 - precision_5: 0.8729 - recall_5: 0.8376\nEpoch 14/50\n63/63 [==============================] - 34s 538ms/step - loss: 0.3485 - accuracy: 0.8651 - auc: 0.9669 - precision_5: 0.8790 - recall_5: 0.8496\nEpoch 15/50\n63/63 [==============================] - 35s 549ms/step - loss: 0.3142 - accuracy: 0.8831 - auc: 0.9724 - precision_5: 0.8970 - recall_5: 0.8701\nEpoch 16/50\n63/63 [==============================] - 47s 748ms/step - loss: 0.3117 - accuracy: 0.8841 - auc: 0.9727 - precision_5: 0.8953 - recall_5: 0.8721\nEpoch 17/50\n63/63 [==============================] - 38s 607ms/step - loss: 0.2919 - accuracy: 0.8906 - auc: 0.9756 - precision_5: 0.9022 - recall_5: 0.8806\nEpoch 18/50\n63/63 [==============================] - 35s 550ms/step - loss: 0.3055 - accuracy: 0.8846 - auc: 0.9741 - precision_5: 0.8918 - recall_5: 0.8731\nEpoch 19/50\n63/63 [==============================] - 34s 536ms/step - loss: 0.2794 - accuracy: 0.8951 - auc: 0.9787 - precision_5: 0.9029 - recall_5: 0.8826\nEpoch 20/50\n63/63 [==============================] - 34s 543ms/step - loss: 0.3016 - accuracy: 0.8896 - auc: 0.9744 - precision_5: 0.9001 - recall_5: 0.8776\nEpoch 21/50\n63/63 [==============================] - 35s 548ms/step - loss: 0.2699 - accuracy: 0.9015 - auc: 0.9796 - precision_5: 0.9102 - recall_5: 0.8911\nEpoch 22/50\n63/63 [==============================] - 34s 536ms/step - loss: 0.2561 - accuracy: 0.9005 - auc: 0.9813 - precision_5: 0.9122 - recall_5: 0.8936\nEpoch 23/50\n63/63 [==============================] - 35s 551ms/step - loss: 0.2536 - accuracy: 0.9005 - auc: 0.9824 - precision_5: 0.9086 - recall_5: 0.8946\nEpoch 24/50\n63/63 [==============================] - 34s 539ms/step - loss: 0.2414 - accuracy: 0.9035 - auc: 0.9835 - precision_5: 0.9153 - recall_5: 0.8961\nEpoch 25/50\n63/63 [==============================] - 34s 544ms/step - loss: 0.2225 - accuracy: 0.9245 - auc: 0.9852 - precision_5: 0.9334 - recall_5: 0.9170\nEpoch 26/50\n63/63 [==============================] - 35s 548ms/step - loss: 0.2377 - accuracy: 0.9050 - auc: 0.9845 - precision_5: 0.9119 - recall_5: 0.9005\nEpoch 27/50\n63/63 [==============================] - 34s 540ms/step - loss: 0.2190 - accuracy: 0.9175 - auc: 0.9863 - precision_5: 0.9240 - recall_5: 0.9110\nEpoch 28/50\n63/63 [==============================] - 35s 552ms/step - loss: 0.2254 - accuracy: 0.9225 - auc: 0.9843 - precision_5: 0.9286 - recall_5: 0.9165\nEpoch 29/50\n63/63 [==============================] - 34s 536ms/step - loss: 0.2118 - accuracy: 0.9235 - auc: 0.9875 - precision_5: 0.9292 - recall_5: 0.9180\nEpoch 30/50\n63/63 [==============================] - 35s 553ms/step - loss: 0.1953 - accuracy: 0.9295 - auc: 0.9888 - precision_5: 0.9342 - recall_5: 0.9220\nEpoch 31/50\n63/63 [==============================] - 35s 555ms/step - loss: 0.1952 - accuracy: 0.9295 - auc: 0.9887 - precision_5: 0.9372 - recall_5: 0.9250\nEpoch 32/50\n63/63 [==============================] - 35s 550ms/step - loss: 0.1894 - accuracy: 0.9290 - auc: 0.9893 - precision_5: 0.9335 - recall_5: 0.9265\nEpoch 33/50\n63/63 [==============================] - 36s 564ms/step - loss: 0.1981 - accuracy: 0.9255 - auc: 0.9888 - precision_5: 0.9307 - recall_5: 0.9195\nEpoch 34/50\n63/63 [==============================] - 35s 550ms/step - loss: 0.1868 - accuracy: 0.9320 - auc: 0.9891 - precision_5: 0.9370 - recall_5: 0.9295\nEpoch 35/50\n63/63 [==============================] - 34s 537ms/step - loss: 0.1981 - accuracy: 0.9220 - auc: 0.9883 - precision_5: 0.9255 - recall_5: 0.9190\nEpoch 36/50\n63/63 [==============================] - 33s 532ms/step - loss: 0.2138 - accuracy: 0.9160 - auc: 0.9869 - precision_5: 0.9229 - recall_5: 0.9090\nEpoch 37/50\n63/63 [==============================] - 34s 538ms/step - loss: 0.1644 - accuracy: 0.9430 - auc: 0.9913 - precision_5: 0.9489 - recall_5: 0.9375\nEpoch 38/50\n63/63 [==============================] - 34s 538ms/step - loss: 0.1959 - accuracy: 0.9245 - auc: 0.9889 - precision_5: 0.9294 - recall_5: 0.9215\nEpoch 39/50\n63/63 [==============================] - 34s 538ms/step - loss: 0.1726 - accuracy: 0.9390 - auc: 0.9905 - precision_5: 0.9416 - recall_5: 0.9350\nEpoch 40/50\n63/63 [==============================] - 35s 550ms/step - loss: 0.1554 - accuracy: 0.9445 - auc: 0.9921 - precision_5: 0.9468 - recall_5: 0.9430\nEpoch 41/50\n63/63 [==============================] - 34s 534ms/step - loss: 0.1479 - accuracy: 0.9430 - auc: 0.9935 - precision_5: 0.9461 - recall_5: 0.9395\nEpoch 42/50\n63/63 [==============================] - 34s 544ms/step - loss: 0.1654 - accuracy: 0.9360 - auc: 0.9910 - precision_5: 0.9388 - recall_5: 0.9345\nEpoch 43/50\n63/63 [==============================] - 34s 546ms/step - loss: 0.1510 - accuracy: 0.9405 - auc: 0.9930 - precision_5: 0.9414 - recall_5: 0.9385\nEpoch 44/50\n63/63 [==============================] - 34s 537ms/step - loss: 0.1525 - accuracy: 0.9415 - auc: 0.9928 - precision_5: 0.9441 - recall_5: 0.9370\nEpoch 45/50\n63/63 [==============================] - 35s 549ms/step - loss: 0.1525 - accuracy: 0.9480 - auc: 0.9930 - precision_5: 0.9493 - recall_5: 0.9455\nEpoch 46/50\n63/63 [==============================] - 34s 544ms/step - loss: 0.1413 - accuracy: 0.9470 - auc: 0.9945 - precision_5: 0.9487 - recall_5: 0.9435\nEpoch 47/50\n63/63 [==============================] - 35s 555ms/step - loss: 0.1395 - accuracy: 0.9475 - auc: 0.9936 - precision_5: 0.9493 - recall_5: 0.9450\nEpoch 48/50\n63/63 [==============================] - 35s 553ms/step - loss: 0.1516 - accuracy: 0.9445 - auc: 0.9928 - precision_5: 0.9487 - recall_5: 0.9425\nEpoch 49/50\n63/63 [==============================] - 34s 546ms/step - loss: 0.1368 - accuracy: 0.9505 - auc: 0.9943 - precision_5: 0.9537 - recall_5: 0.9475\nEpoch 50/50\n63/63 [==============================] - 35s 558ms/step - loss: 0.1376 - accuracy: 0.9480 - auc: 0.9945 - precision_5: 0.9513 - recall_5: 0.9460\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# test generator\ntest_gen = test_.flow_from_dataframe(test_data,\n                                        x_col='path',\n                                        y_col='label',\n                                        target_size=(IMAGE_HEIGTH, IMAGE_WIDTH),\n                                        batch_size=BATCH_SIZE,\n                                        shuffle=True,\n                                        seed=2020,\n                                        class_mode='categorical')\n\n\n# Testing Evaluation\nprint()\nprint('Evaluating on testing data...')\ntest_loss, test_accuarcy, test_auc, test_precision, test_recall = model.evaluate(test_gen)","execution_count":20,"outputs":[{"output_type":"stream","text":"Found 300 validated image filenames belonging to 3 classes.\n\nEvaluating on testing data...\n10/10 [==============================] - 2s 216ms/step - loss: 0.8274 - accuracy: 0.8167 - auc: 0.9201 - precision_5: 0.8161 - recall_5: 0.8133\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation and Results"},{"metadata":{},"cell_type":"markdown","source":"Training evaluation on kfolds. Taking average of all metrics produced by models trained on each fold for both training and validation data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Data metrics\nprint('Training Scores -')\nprint(f'Average Training Loss : {np.mean(train_losses)}')\nprint(f'Average Training Accuracy : {np.mean(train_accuracies)}')\nprint(f'Average training AUC : {np.mean(train_aucs)}')\nprint(f'Average Train Precision : {np.mean(train_precisions)}')\nprint(f'Average Train Recall : {np.mean(train_recalls)}')","execution_count":21,"outputs":[{"output_type":"stream","text":"Training Scores -\nAverage Training Loss : 0.29458218812942505\nAverage Training Accuracy : 0.8981886506080627\nAverage training AUC : 0.9770141243934631\nAverage Train Precision : 0.9146183729171753\nAverage Train Recall : 0.8831980228424072\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validation Data metrics\nprint('Validation Scores -')\nprint(f'Average Validation Loss : {np.mean(val_losses)}')\nprint(f'Average Validation Accuracy : {np.mean(val_accuracies)}')\nprint(f'Average Validation AUC : {np.mean(val_aucs)}')\nprint(f'Average Validation Precision : {np.mean(val_precisions)}')\nprint(f'Average Validation Recall : {np.mean(val_recalls)}')","execution_count":22,"outputs":[{"output_type":"stream","text":"Validation Scores -\nAverage Validation Loss : 0.548412561416626\nAverage Validation Accuracy : 0.7925000190734863\nAverage Validation AUC : 0.9281311631202698\nAverage Validation Precision : 0.8129870295524597\nAverage Validation Recall : 0.7825000286102295\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Testing Evaluation\n\nTesting evaluation is done after training model on full dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing Data Metrics\nprint(f'Test Loss: {test_loss}')\nprint(f'Test Accuracy: {test_accuarcy}')\nprint(f'Test AUC: {test_auc}')\nprint(f'Test Precision: {test_precision}')\nprint(f'Test Recall : {test_recall}')","execution_count":23,"outputs":[{"output_type":"stream","text":"Test Loss: 0.8273851871490479\nTest Accuracy: 0.8166666626930237\nTest AUC: 0.9201111793518066\nTest Precision: 0.8160535097122192\nTest Recall : 0.8133333325386047\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Getting prediction on test data after tarining on full dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting predictions\npred = model.predict(test_gen)\npred = np.argmax(pred, axis=-1)\n\n# True labels\ntrue = test_gen.labels\ntrue = (np.array(true))","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen.class_indices","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"{'Covid': 0, 'Normal': 1, 'Others': 2}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"array([1, 1, 2, 0, 1, 1, 0, 1, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1,\n       2, 1, 1, 0, 2, 1, 1, 2, 2, 1, 0, 2, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0,\n       0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 2, 0, 1,\n       1, 0, 2, 2, 0, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n       0, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 2, 1, 0, 2, 2, 1, 1, 0, 1, 2, 1,\n       1, 0, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n       2, 1, 0, 2, 0, 1, 0, 1, 1, 2, 0, 1, 0, 1, 0, 2, 0, 0, 1, 2, 0, 0,\n       0, 2, 2, 2, 0, 1, 1, 0, 0, 0, 1, 0, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1,\n       0, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 0, 0, 1, 2, 1, 2, 0, 2, 1, 1, 2,\n       1, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2, 0, 2, 0,\n       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 1, 0, 0, 2, 0, 1, 1, 2, 1,\n       0, 2, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n       1, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 2, 0, 0, 1, 1, 1, 0, 2, 0, 0, 1,\n       0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 0, 0, 0, 2])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"true","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(true, pred)","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"array([[28, 47, 25],\n       [24, 49, 27],\n       [37, 39, 24]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the confusion matrix\ncm  = confusion_matrix(true, pred)\n\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(3), ['Normal', 'Covid', 'Others'], fontsize=16)\nplt.yticks(range(3), ['Normal', 'Covid', 'Others'], fontsize=16)\nplt.show()","execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x576 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"## Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"report = classification_report(true, pred, target_names = ['Normal', 'Covid', 'Others'])\nprint(report)","execution_count":29,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n      Normal       0.31      0.28      0.30       100\n       Covid       0.36      0.49      0.42       100\n      Others       0.32      0.24      0.27       100\n\n    accuracy                           0.34       300\n   macro avg       0.33      0.34      0.33       300\nweighted avg       0.33      0.34      0.33       300\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"# def get_roc_curve(labels, predicted_vals, generator):\n#     auc_roc_vals = []\n#     for i in range(len(labels)):\n#         try:\n#             gt = generator[:, i]\n#             pred = predicted_vals[:, i]\n#             auc_roc = roc_auc_score(gt, pred)\n#             auc_roc_vals.append(auc_roc)\n#             fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n#             plt.figure(1, figsize=(10, 10))\n#             plt.plot([0, 1], [0, 1], 'k--')\n#             plt.plot(fpr_rf, tpr_rf,\n#                      label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n#             plt.xlabel('False positive rate')\n#             plt.ylabel('True positive rate')\n#             plt.title('ROC curve')\n#             plt.legend(loc='best')\n#         except:\n#             print(\n#                 f\"Error in generating ROC curve for {labels[i]}. \"\n#                 f\"Dataset lacks enough examples.\"\n#             )\n#     plt.show()\n#     return auc_roc_vals","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# disease_labels = ['Covid', 'Normal', 'Other']\n# get_roc_curve(disease_labels, pred, true)","execution_count":28,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}